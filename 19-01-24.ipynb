{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61288464",
   "metadata": {},
   "source": [
    "# January 19, 2024 - Session Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a717889",
   "metadata": {},
   "source": [
    "##### 1. Loading OpenAI model and getting the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c39ab-92ac-48e6-9196-62b783ff4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(openai_api_key=\"paste your OpenAI API key here!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ce931-5e6e-4d70-95cd-25224e0e641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9b5c9-3918-43ba-b014-1da2d41bc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in llm.batch(['Who is the top hero in Telugu industry','Tell me a funny joke']):\n",
    "    print(result, end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6f2fd-bdb4-40f2-8590-d773586eb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2383f3-6f5a-49f9-b926-29d21b9bff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.max_context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94f4e1-a1be-4a91-a0c0-161d993325f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613f45b-7858-4d3e-b958-8e6226c2af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Who is the president of India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f9b45-c50f-4751-a506-bcf89b761c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6927a",
   "metadata": {},
   "source": [
    "##### 2. Loading GoogleAI Chat model and getting the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd8830-64f6-4827-a121-f6aa14e734a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30868de1-9b54-4884-838e-3733ae5f4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGoogleGenerativeAI(model = \"gemini-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Who is the first person to land on moon?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b8f8e",
   "metadata": {},
   "source": [
    "##### 3. Prompt Template\n",
    "\n",
    "PromptTemplate is a class in LangChain that helps construct prompts with dynamic inputs. It simplifies the process of prompts and allows for the addition of multiple parameters. It is an object-oriented approach to building prompts.\n",
    "\n",
    "Here are some other prompt templates in LangChain:\n",
    "\n",
    "- `SystemMessagePromTemplate` : This is used to define a system message that sets the stage for the conversation. It can include instructions for the model and specify the desired tone or behavior.\n",
    "- `HumanMessagePromptTemplate` : This is used to define a message from a human user. It typically includes a query or request for information.\n",
    "- `AIMessagePromptTemplate` : This is used to define a message from the AI model. It typically includes the model's response to the human's query.\n",
    "- `FewShotPromptTemplate` : This is used to provide examples to the model within the prompt. It allows for few-shot learning, where the model is \"trained\" on a few examples before being asked the actual question.\n",
    "\n",
    "These prompt templates can be combined and customized to create complex prompts for various use cases. By using these templates, developers can create consistent and effective prompts for their language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf1143-5f23-414a-9600-4237ebc8527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1679c2-b123-4a22-97c4-577f7d1fed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "systempl = \"You are an AI tutor for {level} grade students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf27f5-2ee0-41ce-be42-01c5bc21b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysmsg=SystemMessagePromptTemplate.from_template(systempl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386d307-8b70-4180-98ad-f0bf88755c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "humtempl = \"Tell me a {adjective} about {planet}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644bbe6-951b-4122-9a7b-190363019c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummsg = HumanMessagePromptTemplate.from_template(humtempl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a35eac-ef46-4eb4-a6ba-8c1f0bcd57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatprompt = ChatPromptTemplate.from_messages([sysmsg,hummsg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b90a2-9e25-4445-90f7-66032108bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chatprompt.format_prompt(level = '2nd', adjective='funny fact', planet='venus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbdaa8-e8e0-4423-8f3a-a03f8712594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1cc472-7997-49d0-8796-da5ad2644fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f334dc",
   "metadata": {},
   "source": [
    "<<< End Of Document >>>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
